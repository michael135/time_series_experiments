{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ee23497e387c08e1aa0b7c1a9af658812677a87"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, I go through how I worked to find a decent solution for this challenge using simple uncomplicated techniques. No machine learning, no fancy black-box models. Throw away your ARIMAs and Gradient Boosts. Think simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c265d5f4c10385ed1d763e52e182dbb17ea5122b"
   },
   "source": [
    "# Setup and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_uuid": "053e0f77865e9e7351c3a1cc26341f591b1282ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The ipython_unittest extension is already loaded. To reload it, use:\n",
      "  %reload_ext ipython_unittest\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "# %autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext ipython_unittest\n",
    "from math import sin, cos, pi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 896 ms, sys: 127 ms, total: 1.02 s\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = pd.read_csv(\"train.csv\", low_memory=False, \n",
    "                    parse_dates=['date'], index_col=['date'])\n",
    "data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxilary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(A, F):\n",
    "    \"\"\" SMAPE transformation\"\"\"\n",
    "    A, F = A.astype(float), F.astype(float)\n",
    "\n",
    "    return (100. / len(A)) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)  + np.finfo(float).eps))\n",
    "\n",
    " \n",
    "def expand_df(df):\n",
    "    \"\"\"Expand dataframe with more useful columns\"\"\"\n",
    "    data = df.copy()\n",
    "    data['day'] = data.index.day\n",
    "    data['month'] = data.index.month\n",
    "    data['year'] = data.index.year\n",
    "    data['dayofweek'] = data.index.dayofweek\n",
    "    data['week_of_year']  = data.index.weekofyear\n",
    "    return data\n",
    "\n",
    "\n",
    "def cycle(t, T):\n",
    "    \"\"\"transform cyclic feature (hor, day, month) into sin(\\alpha), cos(\\alpha)\"\"\"\n",
    "    arg = 2 * pi * t / T\n",
    "    return sin(arg), cos(arg)\n",
    "\n",
    "\n",
    "def cyclic_features(data, cyclic_features = {'month': 12, 'day' :31, 'dayofweek': 7}):\n",
    "    \"\"\"adding transforming the cyclic feature to sin and cos\"\"\"\n",
    "\n",
    "    for col_name in cyclic_features:\n",
    "        new_cyclic_feature_sin, new_cyclic_feature_cos = [], []\n",
    "        T = cyclic_features[col_name]\n",
    "        print col_name, T\n",
    "        for _, val in data[col_name].iteritems():\n",
    "            temp_sin, temp_cos = cycle(t=val, T=T)\n",
    "            new_cyclic_feature_sin.append(temp_sin)\n",
    "            new_cyclic_feature_cos.append(temp_cos)\n",
    "\n",
    "        data[col_name + '_sin'], data[col_name + '_cos'] = [new_cyclic_feature_sin, new_cyclic_feature_cos]\n",
    "        \n",
    "    return data.drop(columns=cyclic_features, inplace=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/unittest.status+json": {
       "color": "yellow",
       "message": "",
       "previous": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/unittest.status+json": {
       "color": "lightgreen",
       "message": "..\n----------------------------------------------------------------------\nRan 2 tests in 0.000s\n\nOK\n",
       "previous": 0
      },
      "text/plain": [
       "Success"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%unittest_testcase\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def test_smape(self):\n",
    "    \"\"\"to check vairous edge cases where SMAPE implementation may fail\"\"\"\n",
    "    A1, F1 = np.array([1, 2]), np.array([1.1, 2.2])\n",
    "    expected_result1 = 100 * .5 * (.1 / 1.05 + .2 / 2.1)\n",
    "    A2, F2 = np.array([1, 2]), np.array([3, 4])\n",
    "    expected_result2 = 100 * .5 * (2 / 2 + 2. / 3)\n",
    "    A3 = np.arange(101)\n",
    "    F3 = np.arange(101)\n",
    "    F3[100] = 101\n",
    "    expected_result3 = (100. / 101) * (1 / (201. / 2))\n",
    "    \n",
    "    self.assertAlmostEqual(smape(A1,F1), expected_result1, places = 7)\n",
    "    self.assertAlmostEqual(smape(A2,F2), expected_result2, places = 7)\n",
    "    self.assertAlmostEqual(smape(A3,F3), expected_result3, places = 7)\n",
    "    \n",
    "    \n",
    "def test_cycle(self):\n",
    "    \"\"\"To ensure that the distance between minures 58 and 0 is the\n",
    "    same as between 1 and 3\n",
    "    \"\"\"\n",
    "    t1, t2 = 59, 1\n",
    "    t3, t4 = 1, 3\n",
    "    T = 60\n",
    "    self.assertEqual(euclidean(cycle(t1, T), cycle(t2, T)),\n",
    "                     euclidean(cycle(t3, T), cycle(t4, T)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot transformation and Cyclic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addindg Cyclic and One Hot Encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dayofweek 7\n",
      "week_of_year 52\n",
      "day 31\n",
      "month 12\n",
      "CPU times: user 9.44 s, sys: 803 ms, total: 10.2 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = expand_df(data)\n",
    "data = pd.get_dummies(data, columns=[u'store', u'item'])\n",
    "features = {'month': 12, 'day' :31, 'dayofweek': 7, 'week_of_year':52}\n",
    "data = cyclic_features(data, features)\n",
    "\n",
    "test = data.loc['2017-09':, :]\n",
    "train = data.loc[:'2017-08', :]\n",
    "\n",
    "data_x = train.drop(columns='sales').values\n",
    "data_y = train['sales'].values\n",
    "\n",
    "data_test_x = test.drop(columns='sales').values\n",
    "data_test_y = test['sales'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=100,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=20, min_samples_split=20,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=8,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_0 = LinearRegression()\n",
    "regr_1 = DecisionTreeRegressor(max_depth=50)\n",
    "regr_2 = DecisionTreeRegressor(max_depth=200)\n",
    "regr_3 = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=100,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=20, min_samples_split=20,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=8,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "regr_0.fit(data_x, data_y)\n",
    "regr_1.fit(data_x, data_y)\n",
    "regr_2.fit(data_x, data_y)\n",
    "regr_3.fit(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.66853935540901 17.837339757967474 13.445495547733241 20.336638157503923\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_1 = regr_1.predict(data_test_x)\n",
    "y_2 = regr_2.predict(data_test_x)\n",
    "y_3 = regr_3.predict(data_test_x)\n",
    "y_0 = regr_0.predict(data_test_x)\n",
    "\n",
    "\n",
    "print smape(y_1, data_test_y), smape(y_2, data_test_y), smape(y_3, data_test_y), smape(y_0, data_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
